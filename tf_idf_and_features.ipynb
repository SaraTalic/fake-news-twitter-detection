{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428bb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ast\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc02b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d92ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grupa 1: Pozitivne emocije\n",
    "positive_emotions = [\n",
    "    'cheerfulness', 'joy', 'contentment', 'love', 'warmth',\n",
    "    'positive_emotion', 'fun', 'giving', 'friends'\n",
    "]\n",
    "\n",
    "# Grupa 2: Negativne emocije\n",
    "negative_emotions = [\n",
    "    'sadness', 'disgust', 'suffering', 'negative_emotion',\n",
    "    'weakness', 'neglect'\n",
    "]\n",
    "\n",
    "# Grupa 3: Socijalne emocije\n",
    "social_emotions = [\n",
    "    'pride', 'shame', 'politeness', 'affection', 'leader',\n",
    "    'dominant_personality', 'childish', 'trust', 'sympathy'\n",
    "]\n",
    "\n",
    "# Grupa 4: Intenzivne emocije\n",
    "intense_emotions = [\n",
    "    'surprise', 'rage', 'horror', 'fear', 'exasperation',\n",
    "    'nervousness', 'irritability', 'torment', 'pain', 'hate', 'anger'\n",
    "]\n",
    "\n",
    "# Grupa 5: Kognitivno-emotivne emocije\n",
    "cognitive_emotions = [\n",
    "    'anticipation', 'confusion', 'envy', 'disappointment',\n",
    "    'optimism', 'zest', 'achievement'\n",
    "]\n",
    "\n",
    "# Kreiranje novih kolona kao zbir postojeÄ‡ih\n",
    "df['emotion_positive'] = df[[f'empath_result.{x}' for x in positive_emotions]].sum(axis=1)\n",
    "df['emotion_negative'] = df[[f'empath_result.{x}' for x in negative_emotions]].sum(axis=1)\n",
    "df['emotion_social']   = df[[f'empath_result.{x}' for x in social_emotions]].sum(axis=1)\n",
    "df['emotion_intense']  = df[[f'empath_result.{x}' for x in intense_emotions]].sum(axis=1)\n",
    "df['emotion_cognitive'] = df[[f'empath_result.{x}' for x in cognitive_emotions]].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa71d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_users = ['followers_count', 'favourites_count','friends_count',\n",
    "       'statuses_count', 'listed_count', 'cred','BotScore',\n",
    "       'normalize_influence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9143d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_empath = ['emotion_positive', 'emotion_negative',\n",
    "       'emotion_social', 'emotion_intense', 'emotion_cognitive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1857c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['tweet_tokens'] = df['tweet_tokens'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a90278",
   "metadata": {},
   "source": [
    "# TF-IDF + User/Empath Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_text = vectorizer.fit_transform(df['tweet_new_x'])\n",
    "\n",
    "X_users = df[feature_cols_users].values\n",
    "X_empath = df[feature_cols_empath].values\n",
    "X_users_empath = df[feature_cols_users + feature_cols_empath].values\n",
    "\n",
    "X_tfidf_users = hstack([X_text, X_users])\n",
    "X_tfidf_empath = hstack([X_text, X_empath])\n",
    "X_tfidf_users_empath = hstack([X_text, X_users_empath])\n",
    "\n",
    "y = df['BinaryNumTarget'].astype(int)\n",
    "\n",
    "X_train_users, X_test_users, y_train_users, y_test_users = train_test_split(X_tfidf_users, y, test_size=0.2, random_state=1)\n",
    "X_train_empath, X_test_empath, y_train_empath, y_test_empath = train_test_split(X_tfidf_empath, y, test_size=0.2, random_state=1)\n",
    "X_train_users_empath, X_test_users_empath, y_train_users_empath, y_test_users_empath = train_test_split(X_tfidf_users_empath, y, test_size=0.2, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, title):\n",
    "    print(f\"\\nRezultati za: {title}\")\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = metrics.precision_score(y_test, y_pred)\n",
    "        rec = metrics.recall_score(y_test, y_pred)\n",
    "        macro_f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "        weighted_f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        results[name] = (acc, prec, rec, macro_f1, weighted_f1)\n",
    "        print(f\"{name}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1 Macro={macro_f1:.4f}, F1 Weighted={weighted_f1:.4f}\")\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "        print(\"Klasa 0:\", round(df_report.loc['0', 'f1-score'], 3))\n",
    "        print(\"Klasa 1:\", round(df_report.loc['1', 'f1-score'], 3))\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f552e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: TF-IDF + User features\n",
      "Random Forest: Accuracy=0.9728, Precision=0.9753, Recall=0.9720, F1 Macro=0.9728, F1 Weighted=0.9728\n",
      "Klasa 0: 0.972\n",
      "Klasa 1: 0.974\n",
      "Decision Tree: Accuracy=0.9602, Precision=0.9619, Recall=0.9609, F1 Macro=0.9601, F1 Weighted=0.9602\n",
      "Klasa 0: 0.959\n",
      "Klasa 1: 0.961\n",
      "Naive Bayes: Accuracy=0.9356, Precision=0.9319, Recall=0.9443, F1 Macro=0.9355, F1 Weighted=0.9356\n",
      "Klasa 0: 0.933\n",
      "Klasa 1: 0.938\n",
      "KNN: Accuracy=0.6952, Precision=0.7036, Recall=0.7072, F1 Macro=0.6949, F1 Weighted=0.6952\n",
      "Klasa 0: 0.684\n",
      "Klasa 1: 0.705\n",
      "SVM: Accuracy=0.9183, Precision=0.8936, Recall=0.9554, F1 Macro=0.9179, F1 Weighted=0.9181\n",
      "Klasa 0: 0.912\n",
      "Klasa 1: 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:21:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9628, Precision=0.9501, Recall=0.9794, F1 Macro=0.9627, F1 Weighted=0.9628\n",
      "Klasa 0: 0.961\n",
      "Klasa 1: 0.965\n",
      "Logistic Regression: Accuracy=0.9749, Precision=0.9727, Recall=0.9788, F1 Macro=0.9749, F1 Weighted=0.9749\n",
      "Klasa 0: 0.974\n",
      "Klasa 1: 0.976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_users = train_and_evaluate(X_train_users, X_test_users, y_train_users, y_test_users, \"TF-IDF + User features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f08c8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: TF-IDF + Empath features\n",
      "Random Forest: Accuracy=0.9781, Precision=0.9802, Recall=0.9772, F1 Macro=0.9780, F1 Weighted=0.9781\n",
      "Klasa 0: 0.977\n",
      "Klasa 1: 0.979\n",
      "Decision Tree: Accuracy=0.9679, Precision=0.9669, Recall=0.9710, F1 Macro=0.9679, F1 Weighted=0.9679\n",
      "Klasa 0: 0.967\n",
      "Klasa 1: 0.969\n",
      "Naive Bayes: Accuracy=0.9453, Precision=0.9387, Recall=0.9565, F1 Macro=0.9452, F1 Weighted=0.9453\n",
      "Klasa 0: 0.943\n",
      "Klasa 1: 0.948\n",
      "KNN: Accuracy=0.7303, Precision=0.6569, Recall=0.9994, F1 Macro=0.7034, F1 Weighted=0.7063\n",
      "Klasa 0: 0.614\n",
      "Klasa 1: 0.793\n",
      "SVM: Accuracy=0.9890, Precision=0.9873, Recall=0.9914, F1 Macro=0.9890, F1 Weighted=0.9890\n",
      "Klasa 0: 0.989\n",
      "Klasa 1: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [16:35:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9624, Precision=0.9501, Recall=0.9785, F1 Macro=0.9623, F1 Weighted=0.9624\n",
      "Klasa 0: 0.961\n",
      "Klasa 1: 0.964\n",
      "Logistic Regression: Accuracy=0.9744, Precision=0.9726, Recall=0.9780, F1 Macro=0.9744, F1 Weighted=0.9744\n",
      "Klasa 0: 0.973\n",
      "Klasa 1: 0.975\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_empath = train_and_evaluate(X_train_empath, X_test_empath, y_train_empath, y_test_empath, \"TF-IDF + Empath features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719dc60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: TF-IDF + User + Empath features\n",
      "Random Forest: Accuracy=0.9727, Precision=0.9735, Recall=0.9736, F1 Macro=0.9727, F1 Weighted=0.9727\n",
      "Klasa 0: 0.972\n",
      "Klasa 1: 0.974\n",
      "Decision Tree: Accuracy=0.9599, Precision=0.9620, Recall=0.9603, F1 Macro=0.9599, F1 Weighted=0.9599\n",
      "Klasa 0: 0.959\n",
      "Klasa 1: 0.961\n",
      "Naive Bayes: Accuracy=0.9356, Precision=0.9319, Recall=0.9442, F1 Macro=0.9355, F1 Weighted=0.9356\n",
      "Klasa 0: 0.933\n",
      "Klasa 1: 0.938\n",
      "KNN: Accuracy=0.6963, Precision=0.7046, Recall=0.7086, F1 Macro=0.6959, F1 Weighted=0.6963\n",
      "Klasa 0: 0.685\n",
      "Klasa 1: 0.707\n",
      "SVM: Accuracy=0.9178, Precision=0.8938, Recall=0.9542, F1 Macro=0.9175, F1 Weighted=0.9177\n",
      "Klasa 0: 0.912\n",
      "Klasa 1: 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [17:39:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9614, Precision=0.9486, Recall=0.9782, F1 Macro=0.9613, F1 Weighted=0.9614\n",
      "Klasa 0: 0.959\n",
      "Klasa 1: 0.963\n",
      "Logistic Regression: Accuracy=0.9750, Precision=0.9729, Recall=0.9788, F1 Macro=0.9750, F1 Weighted=0.9750\n",
      "Klasa 0: 0.974\n",
      "Klasa 1: 0.976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_users_empath = train_and_evaluate(X_train_users_empath, X_test_users_empath, y_train_users_empath, y_test_users_empath, \"TF-IDF + User + Empath features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ec2b3",
   "metadata": {},
   "source": [
    "# Word2Vec + User/Empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da825c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['tweet_tokens'].tolist()\n",
    "\n",
    "w2v_model = Word2Vec(sentences, vector_size=300, window=10, min_count=5, workers=4, sg=1, negative=10)\n",
    "\n",
    "def vectorize_tweet(tokens):\n",
    "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "    else:\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "X_w2v = np.array([vectorize_tweet(tokens) for tokens in df['tweet_tokens']])\n",
    "X_users = df[feature_cols_users].values\n",
    "X_empath = df[feature_cols_empath].values\n",
    "\n",
    "X_w2v_users = np.hstack([X_w2v, X_users])\n",
    "X_w2v_empath = np.hstack([X_w2v, X_empath])\n",
    "X_w2v_users_empath = np.hstack([X_w2v, X_users, X_empath])\n",
    "\n",
    "y = df['BinaryNumTarget'].astype(int)\n",
    "\n",
    "X_train_w2v_users, X_test_w2v_users, y_train_w2v_users, y_test_w2v_users = train_test_split(X_w2v_users, y, test_size=0.2, random_state=1)\n",
    "X_train_w2v_empath, X_test_w2v_empath, y_train_w2v_empath, y_test_w2v_empath = train_test_split(X_w2v_empath, y, test_size=0.2, random_state=1)\n",
    "X_train_w2v_users_empath, X_test_w2v_users_empath, y_train_w2v_users_empath, y_test_w2v_users_empath = train_test_split(X_w2v_users_empath, y, test_size=0.2, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(), \n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f1adb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: Word2Vec + User\n",
      "Random Forest: Accuracy=0.9565, Precision=0.9518, Recall=0.9645, F1 Macro=0.9564, F1 Weighted=0.9565\n",
      "Klasa 0: 0.955\n",
      "Klasa 1: 0.958\n",
      "Decision Tree: Accuracy=0.8415, Precision=0.8470, Recall=0.8456, F1 Macro=0.8413, F1 Weighted=0.8415\n",
      "Klasa 0: 0.836\n",
      "Klasa 1: 0.846\n",
      "Naive Bayes: Accuracy=0.7899, Precision=0.8106, Recall=0.7736, F1 Macro=0.7899, F1 Weighted=0.7899\n",
      "Klasa 0: 0.788\n",
      "Klasa 1: 0.792\n",
      "KNN: Accuracy=0.8254, Precision=0.8392, Recall=0.8184, F1 Macro=0.8253, F1 Weighted=0.8254\n",
      "Klasa 0: 0.822\n",
      "Klasa 1: 0.829\n",
      "SVM: Accuracy=0.8887, Precision=0.8834, Recall=0.9035, F1 Macro=0.8885, F1 Weighted=0.8886\n",
      "Klasa 0: 0.884\n",
      "Klasa 1: 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [19:27:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9654, Precision=0.9644, Recall=0.9687, F1 Macro=0.9654, F1 Weighted=0.9654\n",
      "Klasa 0: 0.964\n",
      "Klasa 1: 0.967\n",
      "Logistic Regression: Accuracy=0.9066, Precision=0.9072, Recall=0.9123, F1 Macro=0.9065, F1 Weighted=0.9066\n",
      "Klasa 0: 0.903\n",
      "Klasa 1: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': (0.9564812399865866,\n",
       "  0.9517634485215533,\n",
       "  0.9645461766192505,\n",
       "  0.9564151652677509,\n",
       "  0.9564694793189279),\n",
       " 'Decision Tree': (0.8414993107045717,\n",
       "  0.8469660808562957,\n",
       "  0.8456206224276122,\n",
       "  0.8413450085482101,\n",
       "  0.84150336643628),\n",
       " 'Naive Bayes': (0.7898953016133239,\n",
       "  0.8105613557270389,\n",
       "  0.7736298649722002,\n",
       "  0.7898801379497538,\n",
       "  0.789937267717327),\n",
       " 'KNN': (0.8254033309735832,\n",
       "  0.839244724176231,\n",
       "  0.8183984403206007,\n",
       "  0.825339021095346,\n",
       "  0.8254462874747749),\n",
       " 'SVM': (0.8887067327396699,\n",
       "  0.8834368822366563,\n",
       "  0.9035309408621561,\n",
       "  0.8884933770660555,\n",
       "  0.8886494865410425),\n",
       " 'XGBoost': (0.965423450948247,\n",
       "  0.9644166486952771,\n",
       "  0.9687342046357138,\n",
       "  0.9653826866510717,\n",
       "  0.9654207067718898),\n",
       " 'Logistic Regression': (0.9065911546629905,\n",
       "  0.9072238977452247,\n",
       "  0.9122680337930537,\n",
       "  0.9064774088110275,\n",
       "  0.9065817973653396)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(X_train_w2v_users, X_test_w2v_users, y_train_w2v_users, y_test_w2v_users, \"Word2Vec + User\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc67863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: Word2Vec + Empath\n",
      "Random Forest: Accuracy=0.9576, Precision=0.9540, Recall=0.9644, F1 Macro=0.9576, F1 Weighted=0.9576\n",
      "Klasa 0: 0.956\n",
      "Klasa 1: 0.959\n",
      "Decision Tree: Accuracy=0.8418, Precision=0.8485, Recall=0.8441, F1 Macro=0.8417, F1 Weighted=0.8418\n",
      "Klasa 0: 0.837\n",
      "Klasa 1: 0.846\n",
      "Naive Bayes: Accuracy=0.7880, Precision=0.8068, Recall=0.7747, F1 Macro=0.7880, F1 Weighted=0.7880\n",
      "Klasa 0: 0.786\n",
      "Klasa 1: 0.79\n",
      "KNN: Accuracy=0.9873, Precision=0.9877, Recall=0.9877, F1 Macro=0.9873, F1 Weighted=0.9873\n",
      "Klasa 0: 0.987\n",
      "Klasa 1: 0.988\n",
      "SVM: Accuracy=0.9730, Precision=0.9713, Recall=0.9765, F1 Macro=0.9730, F1 Weighted=0.9730\n",
      "Klasa 0: 0.972\n",
      "Klasa 1: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [19:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9670, Precision=0.9662, Recall=0.9700, F1 Macro=0.9670, F1 Weighted=0.9670\n",
      "Klasa 0: 0.966\n",
      "Klasa 1: 0.968\n",
      "Logistic Regression: Accuracy=0.9064, Precision=0.9067, Recall=0.9125, F1 Macro=0.9063, F1 Weighted=0.9064\n",
      "Klasa 0: 0.903\n",
      "Klasa 1: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': (0.9576362755691344,\n",
       "  0.954,\n",
       "  0.9644017618600621,\n",
       "  0.9575761969856464,\n",
       "  0.9576272935234842),\n",
       " 'Decision Tree': (0.8417973844032938,\n",
       "  0.8485156420120491,\n",
       "  0.844104267456134,\n",
       "  0.8416612386662947,\n",
       "  0.8418098399217994),\n",
       " 'Naive Bayes': (0.787995081783971,\n",
       "  0.8067523873975487,\n",
       "  0.7747129756661131,\n",
       "  0.7879669765112134,\n",
       "  0.7880451073503681),\n",
       " 'KNN': (0.9872946085919744,\n",
       "  0.9877238590410168,\n",
       "  0.9876525380893927,\n",
       "  0.9872816106668623,\n",
       "  0.9872946237410711),\n",
       " 'SVM': (0.9729870710533179,\n",
       "  0.9712726228095375,\n",
       "  0.9765326016318868,\n",
       "  0.9729543174535458,\n",
       "  0.9729844409462698),\n",
       " 'XGBoost': (0.9669883378665375,\n",
       "  0.9661943465439113,\n",
       "  0.969961730088815,\n",
       "  0.9669500924722063,\n",
       "  0.9669860758169275),\n",
       " 'Logistic Regression': (0.9064048586012892,\n",
       "  0.9067231111430006,\n",
       "  0.9124846559318363,\n",
       "  0.9062881879471014,\n",
       "  0.9063940169776689)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate(X_train_w2v_empath, X_test_w2v_empath, y_train_w2v_empath, y_test_w2v_empath, \"Word2Vec + Empath\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97a959ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: Word2Vec + User + Empath\n",
      "Random Forest: Accuracy=0.9564, Precision=0.9532, Recall=0.9628, F1 Macro=0.9563, F1 Weighted=0.9564\n",
      "Klasa 0: 0.955\n",
      "Klasa 1: 0.958\n",
      "Decision Tree: Accuracy=0.8414, Precision=0.8475, Recall=0.8446, F1 Macro=0.8412, F1 Weighted=0.8414\n",
      "Klasa 0: 0.836\n",
      "Klasa 1: 0.846\n",
      "Naive Bayes: Accuracy=0.7903, Precision=0.8103, Recall=0.7752, F1 Macro=0.7903, F1 Weighted=0.7904\n",
      "Klasa 0: 0.788\n",
      "Klasa 1: 0.792\n",
      "KNN: Accuracy=0.8263, Precision=0.8398, Recall=0.8198, F1 Macro=0.8262, F1 Weighted=0.8263\n",
      "Klasa 0: 0.823\n",
      "Klasa 1: 0.83\n",
      "SVM: Accuracy=0.8888, Precision=0.8838, Recall=0.9032, F1 Macro=0.8886, F1 Weighted=0.8887\n",
      "Klasa 0: 0.884\n",
      "Klasa 1: 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9655, Precision=0.9651, Recall=0.9682, F1 Macro=0.9655, F1 Weighted=0.9655\n",
      "Klasa 0: 0.964\n",
      "Klasa 1: 0.967\n",
      "Logistic Regression: Accuracy=0.9067, Precision=0.9078, Recall=0.9118, F1 Macro=0.9066, F1 Weighted=0.9067\n",
      "Klasa 0: 0.903\n",
      "Klasa 1: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': (0.9564067215619062,\n",
       "  0.9531774966044749,\n",
       "  0.9628131995089898,\n",
       "  0.9563462404219727,\n",
       "  0.9563982457264801),\n",
       " 'Decision Tree': (0.841387533067551,\n",
       "  0.8474858716128097,\n",
       "  0.8446097191132934,\n",
       "  0.8412422167365702,\n",
       "  0.841395944234492),\n",
       " 'Naive Bayes': (0.7903424121614069,\n",
       "  0.8102641509433962,\n",
       "  0.7752184273232724,\n",
       "  0.7903227348672184,\n",
       "  0.7903877456199414),\n",
       " 'KNN': (0.8262975520697492,\n",
       "  0.839781048894149,\n",
       "  0.8197703805328904,\n",
       "  0.8262300443601247,\n",
       "  0.8263396646296285),\n",
       " 'SVM': (0.8887812511643504,\n",
       "  0.8837784371909001,\n",
       "  0.9032421113437793,\n",
       "  0.8885716619387107,\n",
       "  0.8887263330253297),\n",
       " 'XGBoost': (0.9654979693729274,\n",
       "  0.9650903332613546,\n",
       "  0.9681565455989602,\n",
       "  0.9654588691357231,\n",
       "  0.9654960641564967),\n",
       " 'Logistic Regression': (0.9067401915123514,\n",
       "  0.9078360891445003,\n",
       "  0.9118347895154885,\n",
       "  0.906630481032293,\n",
       "  0.9067329172305214)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate(X_train_w2v_users_empath, X_test_w2v_users_empath, y_train_w2v_users_empath, y_test_w2v_users_empath, \"Word2Vec + User + Empath\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5add4",
   "metadata": {},
   "source": [
    "# FastText + User/Empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "\n",
    "sentences = df['tweet_tokens'].tolist()\n",
    "\n",
    "fasttext_model = FastText(sentences, vector_size=100, window=5, min_count=1, sg=1)\n",
    "fasttext_model.save('fasttext_model.model')\n",
    "\n",
    "def get_vector(tokens, model):\n",
    "    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "X_fasttext = np.array([get_vector(tokens, fasttext_model) for tokens in df['tweet_tokens']])\n",
    "X_users = df[feature_cols_users].values\n",
    "X_empath = df[feature_cols_empath].values\n",
    "\n",
    "X_fasttext_users = np.hstack([X_fasttext, X_users])\n",
    "X_fasttext_empath = np.hstack([X_fasttext, X_empath])\n",
    "X_fasttext_users_empath = np.hstack([X_fasttext, X_users, X_empath])\n",
    "\n",
    "y = df['BinaryNumTarget'].astype(int)\n",
    "\n",
    "X_train_ft_users, X_test_ft_users, y_train_ft_users, y_test_ft_users = train_test_split(X_fasttext_users, y, test_size=0.2, random_state=1)\n",
    "X_train_ft_empath, X_test_ft_empath, y_train_ft_empath, y_test_ft_empath = train_test_split(X_fasttext_empath, y, test_size=0.2, random_state=1)\n",
    "X_train_ft_users_empath, X_test_ft_users_empath, y_train_ft_users_empath, y_test_ft_users_empath = train_test_split(X_fasttext_users_empath, y, test_size=0.2, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC(kernel='linear'),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3e2b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: FastText + User \n",
      "Decision Tree: Accuracy=0.8340, Precision=0.8433, Recall=0.8331, F1 Macro=0.8339, F1 Weighted=0.8340\n",
      "Klasa 0: 0.83\n",
      "Klasa 1: 0.838\n",
      "Random Forest: Accuracy=0.9377, Precision=0.9392, Recall=0.9402, F1 Macro=0.9377, F1 Weighted=0.9377\n",
      "Klasa 0: 0.936\n",
      "Klasa 1: 0.94\n",
      "KNN: Accuracy=0.8035, Precision=0.8188, Recall=0.7951, F1 Macro=0.8034, F1 Weighted=0.8035\n",
      "Klasa 0: 0.8\n",
      "Klasa 1: 0.807\n",
      "SVM: Accuracy=0.7943, Precision=0.7927, Recall=0.8142, F1 Macro=0.7938, F1 Weighted=0.7941\n",
      "Klasa 0: 0.784\n",
      "Klasa 1: 0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [21:21:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9395, Precision=0.9364, Recall=0.9470, F1 Macro=0.9394, F1 Weighted=0.9394\n",
      "Klasa 0: 0.937\n",
      "Klasa 1: 0.942\n",
      "Logistic Regression: Accuracy=0.7911, Precision=0.7923, Recall=0.8066, F1 Macro=0.7907, F1 Weighted=0.7910\n",
      "Klasa 0: 0.782\n",
      "Klasa 1: 0.799\n",
      "Naive Bayes: Accuracy=0.7507, Precision=0.7672, Recall=0.7419, F1 Macro=0.7506, F1 Weighted=0.7507\n",
      "Klasa 0: 0.747\n",
      "Klasa 1: 0.754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': (0.8340102090241812,\n",
       "  0.8433479532163742,\n",
       "  0.8330565383782222,\n",
       "  0.8339004262910586,\n",
       "  0.8340370978385259),\n",
       " 'Random Forest': (0.9377398561794403,\n",
       "  0.9391950375072129,\n",
       "  0.9402122896960069,\n",
       "  0.9376737623194482,\n",
       "  0.9377387218454587),\n",
       " 'KNN': (0.8034576549051753,\n",
       "  0.8187834622248662,\n",
       "  0.7950754567116759,\n",
       "  0.8034004041900352,\n",
       "  0.8035077805313133),\n",
       " 'SVM': (0.7942546294571333,\n",
       "  0.792688927943761,\n",
       "  0.8142104123041375,\n",
       "  0.7938180614833894,\n",
       "  0.7941217148351676),\n",
       " 'XGBoost': (0.9394537799470919,\n",
       "  0.9363844066828502,\n",
       "  0.9469997833778612,\n",
       "  0.9393668909883337,\n",
       "  0.9394403532083861),\n",
       " 'Logistic Regression': (0.7910503371958717,\n",
       "  0.7922547698418327,\n",
       "  0.8065564300671528,\n",
       "  0.7906929703606458,\n",
       "  0.7909697765928001),\n",
       " 'Naive Bayes': (0.7506613510190394,\n",
       "  0.7671918166206227,\n",
       "  0.7419308253303487,\n",
       "  0.7506051214231352,\n",
       "  0.7507249755742065)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate(X_train_ft_users, X_test_ft_users, y_train_ft_users, y_test_ft_users, \"FastText + User \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e0c752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: FastText + Empath\n",
      "Decision Tree: Accuracy=0.8363, Precision=0.8442, Recall=0.8373, F1 Macro=0.8362, F1 Weighted=0.8363\n",
      "Klasa 0: 0.832\n",
      "Klasa 1: 0.841\n",
      "Random Forest: Accuracy=0.9370, Precision=0.9368, Recall=0.9414, F1 Macro=0.9369, F1 Weighted=0.9370\n",
      "Klasa 0: 0.935\n",
      "Klasa 1: 0.939\n",
      "KNN: Accuracy=0.9760, Precision=0.9763, Recall=0.9771, F1 Macro=0.9759, F1 Weighted=0.9760\n",
      "Klasa 0: 0.975\n",
      "Klasa 1: 0.977\n",
      "SVM: Accuracy=0.7954, Precision=0.7922, Recall=0.8181, F1 Macro=0.7949, F1 Weighted=0.7952\n",
      "Klasa 0: 0.785\n",
      "Klasa 1: 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [21:41:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9408, Precision=0.9397, Recall=0.9460, F1 Macro=0.9408, F1 Weighted=0.9408\n",
      "Klasa 0: 0.939\n",
      "Klasa 1: 0.943\n",
      "Logistic Regression: Accuracy=0.7911, Precision=0.7913, Recall=0.8085, F1 Macro=0.7907, F1 Weighted=0.7910\n",
      "Klasa 0: 0.782\n",
      "Klasa 1: 0.8\n",
      "Naive Bayes: Accuracy=0.7485, Precision=0.7648, Recall=0.7402, F1 Macro=0.7484, F1 Weighted=0.7485\n",
      "Klasa 0: 0.745\n",
      "Klasa 1: 0.752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': (0.8363202801892768,\n",
       "  0.8442050087361678,\n",
       "  0.8373167737742797,\n",
       "  0.8361937262916062,\n",
       "  0.8363394498815512),\n",
       " 'Random Forest': (0.9369946719326353,\n",
       "  0.9368352974992814,\n",
       "  0.941367607769514,\n",
       "  0.9369195816260021,\n",
       "  0.9369892388326954),\n",
       " 'KNN': (0.9759678080405381,\n",
       "  0.9763347763347764,\n",
       "  0.9771102606686404,\n",
       "  0.9759425292779862,\n",
       "  0.975967488424),\n",
       " 'SVM': (0.795409665039681,\n",
       "  0.7921968955390855,\n",
       "  0.818109610802224,\n",
       "  0.7949195938428276,\n",
       "  0.7952404560060113),\n",
       " 'XGBoost': (0.9408323708036812,\n",
       "  0.9397460727350979,\n",
       "  0.9459888800635425,\n",
       "  0.9407579904644181,\n",
       "  0.9408251752293256),\n",
       " 'Logistic Regression': (0.7911248556205522,\n",
       "  0.79125150166066,\n",
       "  0.8085060293161961,\n",
       "  0.7907332652743315,\n",
       "  0.791022994910338),\n",
       " 'Naive Bayes': (0.7484630574909646,\n",
       "  0.7647717099373321,\n",
       "  0.740197848220088,\n",
       "  0.7484031924687902,\n",
       "  0.748527405159727)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate(X_train_ft_empath, X_test_ft_empath, y_train_ft_empath, y_test_ft_empath, \"FastText + Empath\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b0e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rezultati za: FastText + User + Empath\n",
      "Decision Tree: Accuracy=0.8329, Precision=0.8417, Recall=0.8329, F1 Macro=0.8328, F1 Weighted=0.8330\n",
      "Klasa 0: 0.828\n",
      "Klasa 1: 0.837\n",
      "Random Forest: Accuracy=0.9368, Precision=0.9369, Recall=0.9410, F1 Macro=0.9368, F1 Weighted=0.9368\n",
      "Klasa 0: 0.935\n",
      "Klasa 1: 0.939\n",
      "KNN: Accuracy=0.8047, Precision=0.8202, Recall=0.7960, F1 Macro=0.8046, F1 Weighted=0.8047\n",
      "Klasa 0: 0.801\n",
      "Klasa 1: 0.808\n",
      "SVM: Accuracy=0.7950, Precision=0.7937, Recall=0.8144, F1 Macro=0.7945, F1 Weighted=0.7948\n",
      "Klasa 0: 0.785\n",
      "Klasa 1: 0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [22:33:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy=0.9406, Precision=0.9393, Recall=0.9460, F1 Macro=0.9405, F1 Weighted=0.9406\n",
      "Klasa 0: 0.938\n",
      "Klasa 1: 0.943\n",
      "Logistic Regression: Accuracy=0.7913, Precision=0.7924, Recall=0.8070, F1 Macro=0.7910, F1 Weighted=0.7912\n",
      "Klasa 0: 0.782\n",
      "Klasa 1: 0.8\n",
      "Naive Bayes: Accuracy=0.7517, Precision=0.7681, Recall=0.7430, F1 Macro=0.7516, F1 Weighted=0.7517\n",
      "Klasa 0: 0.748\n",
      "Klasa 1: 0.755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': (0.8329296918663139,\n",
       "  0.8416636264137176,\n",
       "  0.8329121236190339,\n",
       "  0.8328110365973695,\n",
       "  0.8329535888715279),\n",
       " 'Random Forest': (0.9368456350832743,\n",
       "  0.9368799424874191,\n",
       "  0.941006570871543,\n",
       "  0.9367713405312572,\n",
       "  0.9368407090314559),\n",
       " 'KNN': (0.8046872089124036,\n",
       "  0.8201770701584703,\n",
       "  0.7960141526464004,\n",
       "  0.8046320426248359,\n",
       "  0.8047371154430635),\n",
       " 'SVM': (0.794962554491598,\n",
       "  0.7936664320900774,\n",
       "  0.8143548270633258,\n",
       "  0.794538014623074,\n",
       "  0.7948369324485347),\n",
       " 'XGBoost': (0.9406088155296397,\n",
       "  0.9393417939341794,\n",
       "  0.9459888800635425,\n",
       "  0.9405332078819613,\n",
       "  0.9406010730537018),\n",
       " 'Logistic Regression': (0.7913111516822534,\n",
       "  0.7923993193420307,\n",
       "  0.806989674344718,\n",
       "  0.7909509996945101,\n",
       "  0.7912287111464594),\n",
       " 'Naive Bayes': (0.7516673497522263,\n",
       "  0.7681397432069275,\n",
       "  0.7430139360242617,\n",
       "  0.7516105099415922,\n",
       "  0.7517307695409385)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate(X_train_ft_users_empath, X_test_ft_users_empath, y_train_ft_users_empath, y_test_ft_users_empath, \"FastText + User + Empath\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
